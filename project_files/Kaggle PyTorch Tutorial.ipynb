{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle PyTorch Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "\n",
    "Tensors are matrix like data structures which are essential components in deep learning libraries and efficient computation. GPUs are especially effective at calculating operations between tensors and this has spurred the surge in deep learning capability in recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "#Constructing a 5x3 Matrix Uninitialized\n",
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0e+00, -0.0e+00,  0.0e+00],\n",
       "       [-0.0e+00,  1.4e-44,  0.0e+00],\n",
       "       [ 0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  0.0e+00,  0.0e+00],\n",
       "       [ 0.0e+00,  0.0e+00,  0.0e+00]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert to numpy\n",
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of tensor\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4],\n",
      "        [4, 3]])\n"
     ]
    }
   ],
   "source": [
    "#From Numpy to tensor\n",
    "a = np.array([[3,4],[4,3]])\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0712, 0.4236, 0.4586],\n",
      "        [0.4990, 0.9752, 0.4019],\n",
      "        [0.6712, 0.8402, 0.9017],\n",
      "        [0.7898, 0.7110, 0.7466],\n",
      "        [0.7227, 0.7289, 0.8619]])\n"
     ]
    }
   ],
   "source": [
    "#Random Similar to Numpy\n",
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#Construct a matrix filled zeros and of dtype long\n",
    "x = torch.zeros(5,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5000, 7.0000])\n"
     ]
    }
   ],
   "source": [
    "#Construct a Tensor Directly from data\n",
    "x = torch.tensor([2.5, 7])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "#Create Tensor based on existing tensor\n",
    "x = x.new_ones(5,3, dtype = torch.double)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0812, -0.6023, -0.2009],\n",
      "        [-0.8946,  1.1460, -0.1527],\n",
      "        [-0.7967, -1.2815, -0.6328],\n",
      "        [-0.1852, -0.4925,  0.3003],\n",
      "        [ 0.7516, -0.4257,  0.6923]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1454, 1.6373, 0.6299],\n",
      "        [1.0660, 0.8643, 0.5708],\n",
      "        [0.7958, 1.1046, 0.5513],\n",
      "        [1.1956, 1.2745, 0.9629],\n",
      "        [0.9990, 1.3226, 1.0982]])\n",
      "tensor([[1.1454, 1.6373, 0.6299],\n",
      "        [1.0660, 0.8643, 0.5708],\n",
      "        [0.7958, 1.1046, 0.5513],\n",
      "        [1.1956, 1.2745, 0.9629],\n",
      "        [0.9990, 1.3226, 1.0982]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "\n",
    "print(x+y) # old method\n",
    "print(torch.add(x, y)) # new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1031, -0.4736,  0.0399],\n",
      "        [-0.2063,  0.1103,  0.2393],\n",
      "        [ 0.0936,  0.1453,  0.5804],\n",
      "        [ 0.1050, -0.5389, -0.2557],\n",
      "        [ 0.5181,  0.7308, -0.0297]])\n",
      "tensor([[ 0.1031, -0.4736,  0.0399],\n",
      "        [-0.2063,  0.1103,  0.2393],\n",
      "        [ 0.0936,  0.1453,  0.5804],\n",
      "        [ 0.1050, -0.5389, -0.2557],\n",
      "        [ 0.5181,  0.7308, -0.0297]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "print(x-y) #old method\n",
    "print(torch.sub(x,y)) #new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7615, 0.6403, 0.7220],\n",
      "        [0.2847, 1.4486, 2.8432],\n",
      "        [0.3599, 0.0794, 1.3748],\n",
      "        [0.6004, 0.7895, 0.9554],\n",
      "        [0.0237, 1.4722, 1.1348]])\n",
      "tensor([[0.7615, 0.6403, 0.7220],\n",
      "        [0.2847, 1.4486, 2.8432],\n",
      "        [0.3599, 0.0794, 1.3748],\n",
      "        [0.6004, 0.7895, 0.9554],\n",
      "        [0.0237, 1.4722, 1.1348]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "print(x/y) #old method\n",
    "print(torch.div(x,y)) #new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4206, 0.0924, 0.1145],\n",
      "        [0.6642, 0.4903, 0.0090],\n",
      "        [0.0643, 0.0450, 0.5209],\n",
      "        [0.3711, 0.2475, 0.0939],\n",
      "        [0.0494, 0.1897, 0.3984]])\n",
      "tensor([[0.4206, 0.0924, 0.1145],\n",
      "        [0.6642, 0.4903, 0.0090],\n",
      "        [0.0643, 0.0450, 0.5209],\n",
      "        [0.3711, 0.2475, 0.0939],\n",
      "        [0.0494, 0.1897, 0.3984]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "y = torch.rand(5,3)\n",
    "print(x*y) #old method\n",
    "print(torch.mul(x, y)) #new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2978, 0.8710, 0.8451],\n",
      "        [1.6340, 1.4689, 0.2128],\n",
      "        [0.5093, 0.4246, 1.4618],\n",
      "        [1.2563, 1.0148, 0.6347],\n",
      "        [0.5006, 1.0808, 1.2776]])\n"
     ]
    }
   ],
   "source": [
    "#Adds x to y\n",
    "#New Value is now inside y\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7474, 0.5129, 0.2220, 0.4076, 0.8603])\n"
     ]
    }
   ],
   "source": [
    "#Standard Numpy like indexing\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "#Resizing\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8) # The Size -1 is inferred from other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable\n",
    "\n",
    "The difference between pytorch and numpy is that is provides automatic derivation, which can automatically give you the gradient of the parameters you want. This operation is provided by another basic element, Variable\n",
    "\n",
    "A variable wraps a Tensor. It supports nearly all the APIs defined by a Tensor. Variable also provides a backward method to perform backpropagation. For example, to backpropagate a loss function to train model parameter x, we use a variable loss to store the value computed by a loss function. Then, we call loss.backward which computes the gradient ∂loss∂x for all the trainable parameters. Pytorch will store the gradient results back in the corresponding variable x\n",
    "\n",
    "Variable in torch is to build a computational graph, but this graph is dynamic compared with a static graph in tensorflow or theano. So torch does not have placeholder, torch can just pass variable to the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Build a tensor\n",
    "#Build a variable, usually for compute gradients\n",
    "\n",
    "tensor = torch.FloatTensor([[1,2], [3,4]])\n",
    "variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "print(tensor)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now the tensor and variable seem the same. However, the variable is a part of the graph, its a part of the auto-gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5000)\n",
      "tensor(7.5000, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "t_out = torch.mean(tensor*tensor)\n",
    "v_out = torch.2(variable*variable)\n",
    "\n",
    "print(t_out)\n",
    "print(v_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Backpropagation from v_out\n",
    "* v_out = 1/4 * sum(variable * variable)\n",
    "* the gradients with respect to the variable d(v_out)/d(variable) = 1/4 * 2 * variable = variable/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "v_out.backward()\n",
    "print(variable.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is data in variable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
